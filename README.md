# Data Cleaning Project

## ğŸ“ project structure

(Updated v1.1 28/03/2025)
project/
â”œâ”€â”€ data/                    # Raw CSV data
â”œâ”€â”€ cleaned_data/            # Data after preliminary cleaning
â”œâ”€â”€ cleaned_data_strict/     # Store deduplicated data
â”œâ”€â”€ config/
â”‚   â””â”€â”€ column_types_master.csv
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ missing_values_report.csv
â”‚   â””â”€â”€ relation_integrity_report.csv
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ removed_rows/        # To store deleted data
â”‚   â””â”€â”€ main.log             # Main program run log
â””â”€â”€ scripts/
    â”œâ”€â”€ main.py
    â”œâ”€â”€ clean_missing.py
    â”œâ”€â”€ clean_format.py
    â”œâ”€â”€ clean_relations.py
    â””â”€â”€ clean_missing_strict.py

## ğŸ§© What the module does

### `clean_missing.py`
- Count the number of missing values per column in each CSV file
- Output: 'reports/missing_values_report.csv'

### `clean_format.py`
- Clean each column according to 'column_types_master.csv'
- Types supported: integer, real, date, timestamp, text
- Output: 'cleaned_data/'

### `clean_relations.py`
- Automatic identification of many-to-many relational tables
- Check if foreign key fields are missing or duplicated
- Output: 'reports/relation_integrity_report.csv'

### `main.py`
- Main program entry point
- All three modules are called sequentially
- Automatically log runs to 'logs/main.log'

### `clean_missing_strict.py`
- Load only 19GrantByPersonByDate.csv from cleaned_data/
- Remove full-duplicate rows
- Save cleaned version into cleaned_data_strict/
- Save duplicate log to logs/removed_rows/


## âœ… Start up

```bash
python scripts/main.py
python scripts/main.py --strict_only